{"paragraphs":[{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279117244_1596907171","id":"20160815-093837_1099382913","dateCreated":"2016-08-15T09:38:37-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4025","text":"import org.apache.spark.sql.SparkSession\n\nval spark = SparkSession\n  .builder()\n  .appName(\"Spark SQL Example\")\n  .config(\"spark.some.config.option\", \"some-value\")\n  .getOrCreate()\n\n// For implicit conversions like converting RDDs to DataFrames\nimport spark.implicits._","user":"user1","dateUpdated":"2016-08-15T09:38:53-0700","dateFinished":"2016-08-15T09:38:54-0700","dateStarted":"2016-08-15T09:38:53-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.sql.SparkSession\n\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2254e25\n\nimport spark.implicits._\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279133238_-555747601","id":"20160815-093853_465401636","dateCreated":"2016-08-15T09:38:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4096","user":"user1","dateUpdated":"2016-08-15T09:41:17-0700","dateFinished":"2016-08-15T09:41:18-0700","dateStarted":"2016-08-15T09:41:17-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndf: org.apache.spark.sql.DataFrame = [age: bigint, name: string]\n+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\n"},"text":"val df = spark.read.json(\"file:///Users/vshukla/Downloads/spark-2.0.0-preview-bin-hadoop2.7/examples/src/main/resources/people.json\")\n\n// Displays the content of the DataFrame to stdout\ndf.show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279151038_371344006","id":"20160815-093911_1912727938","dateCreated":"2016-08-15T09:39:11-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4173","user":"user1","dateUpdated":"2016-08-15T09:41:44-0700","dateFinished":"2016-08-15T09:41:44-0700","dateStarted":"2016-08-15T09:41:44-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport spark.implicits._\nroot\n |-- age: long (nullable = true)\n |-- name: string (nullable = true)\n\n"},"text":"import spark.implicits._\ndf.printSchema()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279304130_-2064703783","id":"20160815-094144_652503475","dateCreated":"2016-08-15T09:41:44-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4268","user":"user1","dateUpdated":"2016-08-15T09:41:53-0700","dateFinished":"2016-08-15T09:41:53-0700","dateStarted":"2016-08-15T09:41:53-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"+-------+\n|   name|\n+-------+\n|Michael|\n|   Andy|\n| Justin|\n+-------+\n\n"},"text":"df.select(\"name\").show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279313570_-22826046","id":"20160815-094153_596644786","dateCreated":"2016-08-15T09:41:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4344","user":"user1","dateUpdated":"2016-08-15T09:42:05-0700","dateFinished":"2016-08-15T09:42:06-0700","dateStarted":"2016-08-15T09:42:05-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"+-------+---------+\n|   name|(age + 1)|\n+-------+---------+\n|Michael|     null|\n|   Andy|       31|\n| Justin|       20|\n+-------+---------+\n\n"},"text":"df.select($\"name\", $\"age\" + 1).show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279325842_705919019","id":"20160815-094205_657503487","dateCreated":"2016-08-15T09:42:05-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4420","user":"user1","dateUpdated":"2016-08-15T09:42:14-0700","dateFinished":"2016-08-15T09:42:14-0700","dateStarted":"2016-08-15T09:42:14-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"+---+----+\n|age|name|\n+---+----+\n| 30|Andy|\n+---+----+\n\n"},"text":"df.filter($\"age\" > 21).show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279334202_773081510","id":"20160815-094214_1143021201","dateCreated":"2016-08-15T09:42:14-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4496","user":"user1","dateUpdated":"2016-08-15T09:42:23-0700","dateFinished":"2016-08-15T09:42:24-0700","dateStarted":"2016-08-15T09:42:23-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"+----+-----+\n| age|count|\n+----+-----+\n|  19|    1|\n|null|    1|\n|  30|    1|\n+----+-----+\n\n"},"text":"df.groupBy(\"age\").count().show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279343834_-1455384119","id":"20160815-094223_1507352363","dateCreated":"2016-08-15T09:42:23-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4575","user":"user1","dateUpdated":"2016-08-15T09:42:36-0700","dateFinished":"2016-08-15T09:42:37-0700","dateStarted":"2016-08-15T09:42:36-0700","result":{"code":"SUCCESS","type":"TEXT","msg":""},"text":"df.createOrReplaceTempView(\"people\")\n"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279356985_831578667","id":"20160815-094236_262690982","dateCreated":"2016-08-15T09:42:36-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4656","user":"user1","dateUpdated":"2016-08-15T09:42:47-0700","dateFinished":"2016-08-15T09:42:47-0700","dateStarted":"2016-08-15T09:42:47-0700","result":{"code":"SUCCESS","type":"TEXT","msg":"\nsqlDF: org.apache.spark.sql.DataFrame = [age: bigint, name: string]\n+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\n"},"text":"val sqlDF = spark.sql(\"SELECT * FROM people\")\nsqlDF.show()"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279367536_831224567","id":"20160815-094247_737271556","dateCreated":"2016-08-15T09:42:47-0700","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4732","user":"user1","dateUpdated":"2016-08-15T09:43:09-0700","dateFinished":"2016-08-15T09:43:09-0700","dateStarted":"2016-08-15T09:43:09-0700","result":{"code":"ERROR","type":"TEXT","msg":"java.lang.NoSuchMethodException: org.apache.spark.io.LZ4CompressionCodec.<init>(org.apache.spark.SparkConf)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:72)\n\tat org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:66)\n\tat org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$setConf(TorrentBroadcast.scala:74)\n\tat org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:81)\n\tat org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)\n\tat org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1370)\n\tat org.apache.spark.sql.execution.datasources.json.JsonFileFormat.buildReader(JsonFileFormat.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$class.buildReaderWithPartitionValues(fileSourceInterfaces.scala:260)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(fileSourceInterfaces.scala:304)\n\tat org.apache.spark.sql.execution.datasources.FileSourceStrategy$.apply(FileSourceStrategy.scala:112)\n\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:60)\n\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:60)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:61)\n\tat org.apache.spark.sql.execution.SparkPlanner.plan(SparkPlanner.scala:47)\n\tat org.apache.spark.sql.execution.SparkPlanner$$anonfun$plan$1$$anonfun$apply$1.applyOrElse(SparkPlanner.scala:51)\n\tat org.apache.spark.sql.execution.SparkPlanner$$anonfun$plan$1$$anonfun$apply$1.applyOrElse(SparkPlanner.scala:48)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:301)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:301)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:298)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:298)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:321)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:179)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:319)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:298)\n\tat org.apache.spark.sql.execution.SparkPlanner$$anonfun$plan$1.apply(SparkPlanner.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlanner$$anonfun$plan$1.apply(SparkPlanner.scala:48)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:78)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:76)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2558)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:1924)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2139)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:214)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:129)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:94)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:341)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:176)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n"},"text":"%sql\nselect * from people"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1471279389648_1444914387","id":"20160815-094309_934731711","dateCreated":"2016-08-15T09:43:09-0700","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4808","dateUpdated":"2016-08-15T09:43:19-0700","text":""}],"name":"Spark2.0Note","id":"2BV4BU4CW","angularObjects":{"2BS63B7AE:shared_process":[],"2BT3ANBS2:shared_process":[],"2BUGVSJ52:shared_process":[],"2BUW9WY9X:shared_process":[],"2BSPFD43V:shared_process":[],"2BTNGXTNJ:shared_process":[],"2BUZWB7GR:shared_process":[],"2BVSFUEFP:shared_process":[],"2BU59B72F:shared_process":[],"2BVZ8R8PE:shared_process":[],"2BU2P3ZPQ:shared_process":[],"2BUCTVZZ4:shared_process":[],"2BUHMM7X7:shared_process":[],"2BSGHGQ42:shared_process":[],"2BU8W5A6G:shared_process":[],"2BVPDVFKG:shared_process":[],"2BS7A9XPZ:shared_process":[],"2BTMUJTS9:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}